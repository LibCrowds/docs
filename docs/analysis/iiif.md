The final output from IIIF Annotation projects is a list of annotations
serialised according to the [Web Annotation](https://www.w3.org/annotation/)
data model. Web Annotations are a W3C standard that will integrate with IIIF
APIs and help make the data more easily reusable.

There are currently two main types of annotation that can be generated by
IIIF Annotation projects, selections and transcriptions, where the former
will often be used to generate tasks for the latter. For more details on the
workings of IIIF Annotation projects see the
[creating IIIF Annotation projects](/creating_projects/iiif.md) guide.

## Automated analysis

When a task has recieved the required number of contributions it is marked
as complete and the following results analysis process is triggered.

### 1. Check for any comments

During the task, users have the option to give comments about an image. These
comments are also valid Web Annotations, so if any are found during analysis
they are stored, as given, with the final result.

??? summary "Example result fragment"

    Here is an example of a comment annotation added to the `annotations` key
    of the final result.

    ```json
    {
      "annotations": [
        {
          "body":{
            "type":"TextualBody",
            "purpose":"commenting",
            "value":"I like turtles.",
            "format":"text/plain"
          },
          "motivation":"commenting",
          "target":"https://api.bl.uk/metadata/iiif/ark:/81055/vdc_100022589092.0x0001a3",
          "created":"2017-11-17T15:28:15.088Z",
          "modified":"2017-11-17T15:28:16.255Z",
          "generated":"2017-11-17T15:28:15.088Z",
          "@context":"http://www.w3.org/ns/anno.jsonld",
          "type":"Annotation",
          "id":"4b4ffe2a-b1a4-456f-8bf8-2c02660a3fe5"
        }
        ...
      ]
    }
    ```

### 2. Check for selections

If selection annotations are found (i.e. the IIIF Annotation project that
generated the results was a selection project) then we cluster together any
selections that overlap by a given amount and add these clustered selections
to the final result.

So, if three users marked up the same title, with slightly different regions,
then these three regions should be detected as similar and clustered into one
marked up region. The area for that clustered region is the smallest region
that contains all three sets of original coordinates.

Similarity is determined using the
[Jaccard index](https://en.wikipedia.org/wiki/Jaccard_index), with a result
greater than 0.5. That is, we take two regions, calculate the intersection over
the union, and if the result is greater than 0.5 we merge the two regions.

??? summary "Example result fragment"

    Here is an example of two selections added to the `annotations`
    key of the final result.

    ```json
    {
      "annotations": [
        {
          "body":[
            {
              "type":"TextualBody",
              "purpose":"tagging",
              "value":"title"
            },
            {
              "source":"http://purl.org/dc/terms/title",
              "type":"SpecificResource",
              "purpose":"classifying"
            }
          ],
          "motivation":"tagging",
          "target":{
            "source":"https://api.bl.uk/metadata/iiif/ark:/81055/vdc_100022589092.0x000255",
            "selector":{
              "conformsTo":"http://www.w3.org/TR/media-frags/",
              "type":"FragmentSelector",
              "value":"?xywh=123,333,1462,214"
            }
          },
          "created":"2017-09-16T18:13:31.690Z",
          "modified":"2017-11-17T10:03:40.753139",
          "generated":"2017-09-16T18:13:31.690Z",
          "@context":"http://www.w3.org/ns/anno.jsonld",
          "type":"Annotation",
          "id":"6b55e881-2d8a-4fa7-b983-8428d63df54e"
        },
        {
          "body":[
            {
              "type":"TextualBody",
              "purpose":"tagging",
              "value":"title"
            },
            {
              "source":"http://purl.org/dc/terms/title",
              "type":"SpecificResource",
              "purpose":"classifying"
            }
          ],
          "motivation":"tagging",
          "target":{
            "source":"https://api.bl.uk/metadata/iiif/ark:/81055/vdc_100022589092.0x000255",
            "selector":{
              "conformsTo":"http://www.w3.org/TR/media-frags/",
              "type":"FragmentSelector",
              "value":"?xywh=138,1097,1481,222"
            }
          },
          "created":"2017-09-16T18:13:37.282Z",
          "modified":"2017-11-17T10:03:40.753250",
          "generated":"2017-09-16T18:13:37.282Z",
          "@context":"http://www.w3.org/ns/anno.jsonld",
          "type":"Annotation",
          "id":"ffaa8ac9-1352-4fc9-a78e-4c7f9e9881ba"
        }
      ...
      ]
    }
    ```

### 3. Check for transcriptions

If transcription annotations are found (i.e. the IIIF Annotation project that
generated the results was a transcription project) then we apply some
normalisation rules depending on type of field that was being transcribed
and compare.

| tag     | Normalisation Rules                                               |
|---------|-------------------------------------------------------------------|
| date    | Convert any strings to a date type                                |
| title   | Convert to title case and normalise white space                   |
| genre   | Convert to title case and normalise white space                   |
